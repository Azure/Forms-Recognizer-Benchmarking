{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert OCR Output to target .JSON output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668042704029
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.chdir(\"../\")\n",
        "from utils import *\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668042704365
        }
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "files_ocr = glob.glob('./FR_output/*.json')\n",
        "files_labels = glob.glob('./GT_check/*.json')\n",
        "\n",
        "idx = 0\n",
        "filename_ocr = files_ocr[idx]\n",
        "filename_label = files_labels[idx]\n",
        "\n",
        "\n",
        "with open(f\"./{filename_ocr}\", 'r', encoding=\"utf8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open(f\"./{filename_label}\", 'r', encoding=\"utf8\") as f:\n",
        "    data_label = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666309593121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# convert bounding boxes\n",
        "regx_img_name_png = re.compile(\"(^(.*?)PNG)\")\n",
        "regx_img_name_jpeg = re.compile(\"(^(.*?)jpeg)\")\n",
        "regx_img = re.compile(\"([^\\/]+$)\")\n",
        "\n",
        "if \".PNG\" in filename_ocr:\n",
        "    img_path = regx_img_name_png.findall(filename_ocr)[0][0]\n",
        "if \".jpeg\" in filename_ocr:\n",
        "    img_path = regx_img_name_jpeg.findall(filename_ocr)[0][0]\n",
        "\n",
        "img_name = regx_img.findall(img_path)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666309595426
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "im = Image.open(f'./images/{img_name}')\n",
        "width, height = im.size\n",
        "\n",
        "print(width, height)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parse Document Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### FR Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666309597452
        }
      },
      "outputs": [],
      "source": [
        "base_data = data[\"analyzeResult\"][\"pages\"]\n",
        "\n",
        "#Parse original output\n",
        "page_list2, text_list2,bb_list2, confidence_list2, level2 = parse_text_ocr(base_data)\n",
        "\n",
        "\n",
        "# Format text into target format per page\n",
        "df2 = pd.DataFrame([page_list2, text_list2,bb_list2, confidence_list2, level2]).T\n",
        "df2.columns = [\"page\", \"text\",\"bbox\", \"confidence\", \"level\"]\n",
        "df = df2.copy()\n",
        "#df = pd.concat([df1, df2], axis=0)\n",
        "assert len(df) == len(df[~df.confidence.isna()])\n",
        "# convert bounding boxes\n",
        "df[\"bbox_formatted\"] = [convert_inches_pixel(list(df[\"bbox\"].iloc[i])) for i in range(len(df))] #df[\"bbox\"] \n",
        "df.sample(3)\n",
        "\n",
        "# Iterate by page\n",
        "text_by_page_formatted = []\n",
        "for i in df[\"page\"].unique():\n",
        "    df_page= df[df.page == i]\n",
        "    text_by_page_formatted.append([format_json_sublevel(df_page, u) for u in range(len(df_page))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Label Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666309599540
        }
      },
      "outputs": [],
      "source": [
        "base_data = data_label[\"labels\"]\n",
        "\n",
        "#Parse original output\n",
        "page_list2, text_list2,bb_list2, level_cat = parse_text_labels(base_data)\n",
        "\n",
        "# Format text into target format per page\n",
        "df2 = pd.DataFrame([page_list2, text_list2,bb_list2, level_cat]).T\n",
        "df2.columns = [\"page\", \"text\",\"bbox\", \"level\"]\n",
        "df_label = df2.copy()\n",
        "\n",
        "# convert bounding boxes\n",
        "df_label[\"bbox_formatted\"] = [convert_inches_pixel_normalized_vector(list(df_label[\"bbox\"].iloc[i]), pixel_conv_x=width, pixel_conv_y=height) for i in range(len(df_label))]\n",
        "\n",
        "\n",
        "# Iterate by page\n",
        "text_by_page_formatted_label = []\n",
        "for i in df_label[\"page\"].unique():\n",
        "    df_label_page= df_label[df_label.page == i]\n",
        "    text_by_page_formatted_label.append([format_json_sublevel_label(df_label_page, u) for u in range(len(df_label_page))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parse Tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666309601090
        }
      },
      "outputs": [],
      "source": [
        "try: \n",
        "    base_data_ = data[\"analyzeResult\"][\"pageResults\"] #THIS IS WHEN TABLES ARE PRESENT IN THE DOCUMENT\n",
        "\n",
        "    try:\n",
        "        page_index, text_list3,bb_list3, confidence_, columnIndex, rowIndex, tableIndex =  parse_tables(base_data_)\n",
        "        df_table = pd.DataFrame([page_index, text_list3,bb_list3, confidence_, columnIndex, rowIndex, tableIndex]).T\n",
        "        df_table.columns = [\"page\", \"text\",\"bbox\", \"confidence\", \"columnIndex\", \"rowIndex\", \"tableIndex\"]\n",
        "        df_table[\"bbox_formatted\"] = [convert_inches_pixel(list(df_table[\"bbox\"].iloc[i])) for i in range(len(df_table))]\n",
        "\n",
        "        ###############################\n",
        "        ############ TABLE ############\n",
        "        ###############################\n",
        "        \n",
        "        # iterate per page per table\n",
        "        tables_by_page_formatted = []\n",
        "        for i in df_table.page.unique():\n",
        "            tables_by_page_formatted.append(iterate_table_per_page(df_table[df_table.page == i]))\n",
        "        \n",
        "    except KeyError:\n",
        "        pass\n",
        "except KeyError:\n",
        "    print(\"no tables\")\n",
        "    #IF NO TABLES PRESENT\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OPTIONAL: Format .JSON"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "```\n",
        "try:\n",
        "    assert len(text_by_page_formatted) == len(tables_by_page_formatted)\n",
        "    d_all_pages = [merge_dicts(text_by_page_formatted[ii], tables_by_page_formatted[ii]) for ii in range(len(text_by_page_formatted))]\n",
        "except:\n",
        "    pass\n",
        "    d_all_pages = text_by_page_formatted\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "7013818eacae818f3940355a4bc23a5b5e4daa7053faee37a40d29ac79fa390b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
